# tensorrtPipe
Inference optimization library for tensorrt. Splits up a tensorrt network into multiple engines and uses a pipeline to improve the throughput of the network.

Should be used as followed:
<pre><code>
This is a code block.
</code></pre>

An example can be found in example/
